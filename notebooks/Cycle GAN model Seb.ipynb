{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6df76664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e455e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all images in a directory into memory\n",
    "\n",
    "def load_images(path):\n",
    "    \n",
    "    raw_name_list=os.listdir(path)\n",
    "    \n",
    "    #clean the name list and sort it\n",
    "    clean_name_list = list()\n",
    "    for x in raw_name_list:\n",
    "        if \".jpg\" in x:\n",
    "            clean_name_list.append(x)\n",
    "    clean_name_list.sort()\n",
    "    \n",
    "\t# enumerate filenames in directory\n",
    "    \n",
    "    data_list = [np.asarray(plt.imread(os.path.join(path,filename))) for filename in clean_name_list]\n",
    "    \n",
    "    return np.asarray(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://youtu.be/VzIO5_R9XEM\n",
    "# https://youtu.be/2MSGnkir9ew\n",
    "\"\"\"\n",
    "Cycle GAN: Monet2Photo\n",
    "\n",
    "Dataset from https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# dataset path\n",
    "path = os.path.join(os.getcwd(),\"..\",\"preproc_data\",\"preproc_sketch\")\n",
    "\n",
    "# load dataset A - Monet paintings\n",
    "dataA_all = load_images(path + 'trainA/')\n",
    "print('Loaded dataA: ', dataA_all.shape)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "#To get a subset of all images, for faster training during demonstration\n",
    "dataA = resample(dataA_all, \n",
    "                 replace=False,     \n",
    "                 n_samples=500,    \n",
    "                 random_state=42) \n",
    "\n",
    "# load dataset B - Photos \n",
    "dataB_all = load_images(path + 'trainB/')\n",
    "print('Loaded dataB: ', dataB_all.shape)\n",
    "#Get a subset of all images, for faster training during demonstration\n",
    "#We could have just read the list of files and only load a subset, better memory management. \n",
    "dataB = resample(dataB_all, \n",
    "                 replace=False,     \n",
    "                 n_samples=500,    \n",
    "                 random_state=42) \n",
    "\n",
    "# plot source images\n",
    "n_samples = 3\n",
    "for i in range(n_samples):\n",
    "\tplt.subplot(2, n_samples, 1 + i)\n",
    "\tplt.axis('off')\n",
    "\tplt.imshow(dataA[i].astype('uint8'))\n",
    "# plot target image\n",
    "for i in range(n_samples):\n",
    "\tplt.subplot(2, n_samples, 1 + n_samples + i)\n",
    "\tplt.axis('off')\n",
    "\tplt.imshow(dataB[i].astype('uint8'))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# load image data\n",
    "data = [dataA, dataB]\n",
    "\n",
    "print('Loaded', data[0].shape, data[1].shape)\n",
    "\n",
    "#Preprocess data to change input range to values between -1 and 1\n",
    "# This is because the generator uses tanh activation in the output layer\n",
    "#And tanh ranges between -1 and 1\n",
    "def preprocess_data(data):\n",
    "\t# load compressed arrays\n",
    "\t# unpack arrays\n",
    "\tX1, X2 = data[0], data[1]\n",
    "\t# scale from [0,255] to [-1,1]\n",
    "\tX1 = (X1 - 127.5) / 127.5\n",
    "\tX2 = (X2 - 127.5) / 127.5\n",
    "\treturn [X1, X2]\n",
    "\n",
    "dataset = preprocess_data(data)\n",
    "\n",
    "from cycleGAN_model import define_generator, define_discriminator, define_composite_model, train\n",
    "# define input shape based on the loaded dataset\n",
    "image_shape = dataset[0].shape[1:]\n",
    "# generator: A -> B\n",
    "g_model_AtoB = define_generator(image_shape)\n",
    "# generator: B -> A\n",
    "g_model_BtoA = define_generator(image_shape)\n",
    "# discriminator: A -> [real/fake]\n",
    "d_model_A = define_discriminator(image_shape)\n",
    "# discriminator: B -> [real/fake]\n",
    "d_model_B = define_discriminator(image_shape)\n",
    "# composite: A -> B -> [real/fake, A]\n",
    "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
    "# composite: B -> A -> [real/fake, B]\n",
    "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)\n",
    "\n",
    "from datetime import datetime \n",
    "start1 = datetime.now() \n",
    "# train models\n",
    "train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset, epochs=5)\n",
    "\n",
    "stop1 = datetime.now()\n",
    "#Execution time of the model \n",
    "execution_time = stop1-start1\n",
    "print(\"Execution time is: \", execution_time)\n",
    "\n",
    "############################################\n",
    "\n",
    "# Use the saved cyclegan models for image translation\n",
    "from instancenormalization import InstanceNormalization  \n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "from numpy.random import randint\n",
    "\n",
    "# select a random sample of images from the dataset\n",
    "def select_sample(dataset, n_samples):\n",
    "\t# choose random instances\n",
    "\tix = randint(0, dataset.shape[0], n_samples)\n",
    "\t# retrieve selected images\n",
    "\tX = dataset[ix]\n",
    "\treturn X\n",
    "\n",
    "# plot the image, its translation, and the reconstruction\n",
    "def show_plot(imagesX, imagesY1, imagesY2):\n",
    "\timages = vstack((imagesX, imagesY1, imagesY2))\n",
    "\ttitles = ['Real', 'Generated', 'Reconstructed']\n",
    "\t# scale from [-1,1] to [0,1]\n",
    "\timages = (images + 1) / 2.0\n",
    "\t# plot images row by row\n",
    "\tfor i in range(len(images)):\n",
    "\t\t# define subplot\n",
    "\t\tpyplot.subplot(1, len(images), 1 + i)\n",
    "\t\t# turn off axis\n",
    "\t\tpyplot.axis('off')\n",
    "\t\t# plot raw pixel data\n",
    "\t\tpyplot.imshow(images[i])\n",
    "\t\t# title\n",
    "\t\tpyplot.title(titles[i])\n",
    "\tpyplot.show()\n",
    "\n",
    "# load dataset\n",
    "A_data = resample(dataA_all, \n",
    "                 replace=False,     \n",
    "                 n_samples=50,    \n",
    "                 random_state=42) # reproducible results\n",
    "\n",
    "B_data = resample(dataB_all, \n",
    "                 replace=False,     \n",
    "                 n_samples=50,    \n",
    "                 random_state=42) # reproducible results\n",
    "\n",
    "A_data = (A_data - 127.5) / 127.5\n",
    "B_data = (B_data - 127.5) / 127.5\n",
    "\n",
    "\n",
    "# load the models\n",
    "cust = {'InstanceNormalization': InstanceNormalization}\n",
    "model_AtoB = load_model('monet2photo_models/g_model_AtoB_005935.h5', cust)\n",
    "model_BtoA = load_model('monet2photo_models/g_model_BtoA_005935.h5', cust)\n",
    "\n",
    "# plot A->B->A (Monet to photo to Monet)\n",
    "A_real = select_sample(A_data, 1)\n",
    "B_generated  = model_AtoB.predict(A_real)\n",
    "A_reconstructed = model_BtoA.predict(B_generated)\n",
    "show_plot(A_real, B_generated, A_reconstructed)\n",
    "# plot B->A->B (Photo to Monet to Photo)\n",
    "B_real = select_sample(B_data, 1)\n",
    "A_generated  = model_BtoA.predict(B_real)\n",
    "B_reconstructed = model_AtoB.predict(A_generated)\n",
    "show_plot(B_real, A_generated, B_reconstructed)\n",
    "\n",
    "##########################\n",
    "#Load a single custom image\n",
    "test_image = load_img('monet2photo/sunset256.jpg')\n",
    "test_image = img_to_array(test_image)\n",
    "test_image_input = np.array([test_image])  # Convert single image to a batch.\n",
    "test_image_input = (test_image_input - 127.5) / 127.5\n",
    "\n",
    "# plot B->A->B (Photo to Monet to Photo)\n",
    "monet_generated  = model_BtoA.predict(test_image_input)\n",
    "photo_reconstructed = model_AtoB.predict(monet_generated)\n",
    "show_plot(test_image_input, monet_generated, photo_reconstructed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('shims')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0b5fd8bb318c6605a84b1dde9e3b0ae25013f0abc3ecf985a0c4cd54eac2f8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
